/home/binh/Thesis/Ensemble/data/sample_data_test.csv
['humidity', 'light']
Train base models
Start train DecisionTree model
2022/01/06 11:09:35 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmps45wnteq/model, flavor: spark)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/environment.py", line 196, in infer_pip_requirements
    return _infer_requirements(model_uri, flavor)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 299, in _infer_requirements
    modules = _capture_imported_modules(model_uri, flavor)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 246, in _capture_imported_modules
    json.dumps(sys.path),
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 187, in _run_command
    raise MlflowException(msg)
mlflow.exceptions.MlflowException: Encountered an unexpected error while running ['/usr/bin/python3', '/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py', '--model-path', '/tmp/tmps45wnteq/model', '--flavor', 'spark', '--output-file', '/tmp/tmpczz46juc/imported_modules.txt', '--sys-path', '["/home/binh/Thesis/Ensemble", "/usr/local/lib64/python3.6/site-packages/git/ext/gitdb", "/tmp/spark-17521877-1d5a-48c7-adec-55e004f35dff/userFiles-bb516ed4-5590-4c87-b918-8a0b45a76147", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-core_2.12-3.1.2.jar", "/usr/lib64/python36.zip", "/usr/lib64/python3.6", "/usr/lib64/python3.6/lib-dynload", "/root/.local/lib/python3.6/site-packages", "/usr/local/lib64/python3.6/site-packages", "/usr/local/lib/python3.6/site-packages", "/usr/lib64/python3.6/site-packages", "/usr/lib/python3.6/site-packages", "/usr/local/lib/python3.6/site-packages/gitdb/ext/smmap"]']
exit status: 1
stdout: 
stderr: Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 134, in <module>
    main()
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 109, in main
    mlflow.pyfunc.load_model(model_path)
  File "/usr/local/lib/python3.6/site-packages/mlflow/pyfunc/__init__.py", line 667, in load_model
    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 106, in _load_pyfunc_patch
    return original(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/mlflow/spark.py", line 707, in _load_pyfunc
    .master("local[1]")
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/session.py", line 228, in getOrCreate
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 384, in getOrCreate
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 147, in __init__
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 209, in _do_init
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 321, in _initialize_context
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1569, in __call__
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2629)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2626)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2716)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:95)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)


Train DecisionTree model finish !
Start train SVM model
2022/01/06 11:10:21 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpbk0084xq/model, flavor: spark)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/environment.py", line 196, in infer_pip_requirements
    return _infer_requirements(model_uri, flavor)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 299, in _infer_requirements
    modules = _capture_imported_modules(model_uri, flavor)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 246, in _capture_imported_modules
    json.dumps(sys.path),
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 187, in _run_command
    raise MlflowException(msg)
mlflow.exceptions.MlflowException: Encountered an unexpected error while running ['/usr/bin/python3', '/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py', '--model-path', '/tmp/tmpbk0084xq/model', '--flavor', 'spark', '--output-file', '/tmp/tmpv9dsqrfu/imported_modules.txt', '--sys-path', '["/home/binh/Thesis/Ensemble", "/usr/local/lib64/python3.6/site-packages/git/ext/gitdb", "/tmp/spark-17521877-1d5a-48c7-adec-55e004f35dff/userFiles-bb516ed4-5590-4c87-b918-8a0b45a76147", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-core_2.12-3.1.2.jar", "/usr/lib64/python36.zip", "/usr/lib64/python3.6", "/usr/lib64/python3.6/lib-dynload", "/root/.local/lib/python3.6/site-packages", "/usr/local/lib64/python3.6/site-packages", "/usr/local/lib/python3.6/site-packages", "/usr/lib64/python3.6/site-packages", "/usr/lib/python3.6/site-packages", "/usr/local/lib/python3.6/site-packages/gitdb/ext/smmap"]']
exit status: 1
stdout: 
stderr: Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 134, in <module>
    main()
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 109, in main
    mlflow.pyfunc.load_model(model_path)
  File "/usr/local/lib/python3.6/site-packages/mlflow/pyfunc/__init__.py", line 667, in load_model
    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 106, in _load_pyfunc_patch
    return original(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/mlflow/spark.py", line 707, in _load_pyfunc
    .master("local[1]")
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/session.py", line 228, in getOrCreate
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 384, in getOrCreate
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 147, in __init__
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 209, in _do_init
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 321, in _initialize_context
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1569, in __call__
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2629)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2626)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2716)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:95)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)


Train SVM model finish !
Start train Bayes model
2022/01/06 11:10:26 ERROR mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwbci945a/model, flavor: spark)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/environment.py", line 196, in infer_pip_requirements
    return _infer_requirements(model_uri, flavor)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 299, in _infer_requirements
    modules = _capture_imported_modules(model_uri, flavor)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 246, in _capture_imported_modules
    json.dumps(sys.path),
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/requirements_utils.py", line 187, in _run_command
    raise MlflowException(msg)
mlflow.exceptions.MlflowException: Encountered an unexpected error while running ['/usr/bin/python3', '/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py', '--model-path', '/tmp/tmpwbci945a/model', '--flavor', 'spark', '--output-file', '/tmp/tmpggrvczjh/imported_modules.txt', '--sys-path', '["/home/binh/Thesis/Ensemble", "/usr/local/lib64/python3.6/site-packages/git/ext/gitdb", "/tmp/spark-17521877-1d5a-48c7-adec-55e004f35dff/userFiles-bb516ed4-5590-4c87-b918-8a0b45a76147", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip", "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-core_2.12-3.1.2.jar", "/usr/lib64/python36.zip", "/usr/lib64/python3.6", "/usr/lib64/python3.6/lib-dynload", "/root/.local/lib/python3.6/site-packages", "/usr/local/lib64/python3.6/site-packages", "/usr/local/lib/python3.6/site-packages", "/usr/lib64/python3.6/site-packages", "/usr/lib/python3.6/site-packages", "/usr/local/lib/python3.6/site-packages/gitdb/ext/smmap"]']
exit status: 1
stdout: 
stderr: Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 134, in <module>
    main()
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 109, in main
    mlflow.pyfunc.load_model(model_path)
  File "/usr/local/lib/python3.6/site-packages/mlflow/pyfunc/__init__.py", line 667, in load_model
    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
  File "/usr/local/lib/python3.6/site-packages/mlflow/utils/_capture_modules.py", line 106, in _load_pyfunc_patch
    return original(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/mlflow/spark.py", line 707, in _load_pyfunc
    .master("local[1]")
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/session.py", line 228, in getOrCreate
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 384, in getOrCreate
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 147, in __init__
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 209, in _do_init
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/context.py", line 321, in _initialize_context
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1569, in __call__
  File "/home/binh/spark/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.
: org.apache.spark.SparkException: Only one SparkContext should be running in this JVM (see SPARK-2243).The currently running SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)
	at org.apache.spark.SparkContext$.$anonfun$assertNoOtherContextIsRunning$2(SparkContext.scala:2629)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2626)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2716)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:95)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:238)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)


Train Bayes model finish !
Start cross validation !
Validation for DecisionTree model
Validation for SVM model
Validation for Bayes model
Cross validation finish
Train meta model
Train meta model finish
Traceback (most recent call last):
  File "/home/binh/Thesis/Ensemble/EnsembleStacking.py", line 119, in <module>
    ensemble_stacking.save()
TypeError: save() missing 1 required positional argument: 'path'
